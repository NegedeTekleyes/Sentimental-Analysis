{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56c99b3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# setup and verification\n",
    "print(\"Intializing sentiment analysis project\")\n",
    "print(\"=\" *50)\n",
    "#  import packages\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import(\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    pipeline,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import gradio as gr\n",
    "import os\n",
    "from google.colab import drive\n",
    "#  verify envt\n",
    "print(\"Enviroment checked\")\n",
    "print(f\"pytorch version: {torch.__version__}\")\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "  print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "  # print(f\"Gpu memory: {torch.cuda.get_device_properties(0).total_memort /1e9:.1f} GB\")\n",
    "  # create project structuere\n",
    "  os.makedirs('/content/models', exist_ok=True)\n",
    "  os.makedirs('/content/results', exist_ok=True)\n",
    "  print(\"Project directories created\")\n",
    "\n",
    "  print(\"Ready to start project\")\n",
    "  print(\"=\" *50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1f0af5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# data loading and exploration\n",
    "print(\"Loading and exploring dataset\")\n",
    "print(\"=\" *50)\n",
    "def load_and_explore_data():\n",
    "  \"\"\"Load IMDB dataset and provide comprehensive analysis\"\"\"\n",
    "  print(\"1. Downloading IMDB dataset...\")\n",
    "  dataset = load_dataset(\"imdb\")\n",
    "\n",
    "  print(\"2. Dataset structure:\")\n",
    "  print(f\" -Train samples: {len(dataset['train']):,}\")\n",
    "  print(f\" -Train samples: {len(dataset['test']):,}\")\n",
    "  print(f\" -Validation samples: {len(dataset['unsupervised']):,}\")\n",
    "\n",
    "  print(\"3. Sample data preview:\")\n",
    "  sample_data = dataset['train'].select(range(3))\n",
    "  for i, example in enumerate(sample_data):\n",
    "    print(f\" Sample{i+1}:\")\n",
    "    # Fix: Use example['text'] instead of sample['text']\n",
    "    print(f\" Text: {example['text'][:100]}...\")\n",
    "    print(f\" label: {example['label']} ({'Positive' if example['label'] == 1 else 'Negative'})\")\n",
    "    print()\n",
    "\n",
    "  # LABEL DISTRIBUTUION - Moved inside the function\n",
    "  train_labels = dataset['train']['label']\n",
    "  positive_count = sum(train_labels)\n",
    "  # Fix: calculate negative_count correctly\n",
    "  negative_count = len(train_labels) - positive_count\n",
    "  print(\"4. Label distribution:\")\n",
    "  print(f\"   - Positive reviews: {positive_count:,} ({positive_count/len(train_labels)*100:.1f}%)\")\n",
    "  print(f\"   - Negative reviews: {negative_count:,} ({negative_count/len(train_labels)*100:.1f}%)\")\n",
    "\n",
    "  return dataset\n",
    "\n",
    "dataset = load_and_explore_data()\n",
    "print(\"Data set loaded successfully\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
