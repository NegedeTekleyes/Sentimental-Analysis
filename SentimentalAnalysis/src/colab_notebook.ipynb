{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56c99b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Libraries you already had\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Optional: version info for reproducibility\n",
    "import transformers\n",
    "import datasets\n",
    "\n",
    "# Try to import Colab drive only in Colab\n",
    "IN_COLAB = False\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# Basic logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "log.info(f\"Python: {sys.version.splitlines()[0]}\")\n",
    "log.info(f\"PyTorch: {torch.__version__}\")\n",
    "log.info(f\"Transformers: {transformers.__version__}\")\n",
    "log.info(f\"Datasets: {datasets.__version__}\")\n",
    "\n",
    "# device selection\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "log.info(f\"Using device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    try:\n",
    "        dev_idx = torch.cuda.current_device()\n",
    "        props = torch.cuda.get_device_properties(dev_idx)\n",
    "        total_gb = props.total_memory / 1e9\n",
    "        log.info(f\"GPU device: {torch.cuda.get_device_name(dev_idx)} ({total_gb:.1f} GB)\")\n",
    "    except Exception as e:\n",
    "        log.warning(f\"Could not query GPU properties: {e}\")\n",
    "\n",
    "# project directories (configurable)\n",
    "PROJECT_ROOT = Path(os.getenv(\"PROJECT_ROOT\", \"/content\" if IN_COLAB else \".\"))  # change default if not Colab\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
    "for d in (MODELS_DIR, RESULTS_DIR):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "    log.info(f\"Ensured directory: {d.resolve()}\")\n",
    "\n",
    "# reproducibility\n",
    "SEED = int(os.getenv(\"SEED\", 42))\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Optional: cudnn deterministic for reproducibility (can slow training)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "log.info(\"Environment ready. Ready to start project\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1f0af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading and exploration\n",
    "from datasets import load_dataset # Import load_dataset\n",
    "\n",
    "print(\"Loading and exploring dataset\")\n",
    "print(\"=\" *50)\n",
    "def load_and_explore_data(dataset_name = \"imdb\", sample_size=5):\n",
    "  \"\"\"Load IMDB dataset and provide comprehensive analysis\"\"\"\n",
    "  print(\"1.Downloading IMDB dataset...\")\n",
    "  try:\n",
    "    dataset = load_dataset(dataset_name)\n",
    "    print(\"Dataset downloaded successfully.\")\n",
    "  except Exception as e: # Corrected typo: 'excep' to 'except'\n",
    "    print(\"Failed to load dataset:\", e)\n",
    "    return None\n",
    "\n",
    "# basic structure\n",
    "  print(\"2. Dataset structure:\")\n",
    "  for split in dataset.keys():\n",
    "    print(f\" -{split.capitalize()} samples: {len(dataset[split]):,}\")\n",
    "\n",
    "# preview sample\n",
    "  print(\"3. Sample data preview:\")\n",
    "  sample_data = dataset['train'].select(range(sample_size))\n",
    "  for i, example in enumerate(sample_data):\n",
    "    print(f\"   Sample{i+1}:\") # Adjusted indentation\n",
    "    text_previeww = example[\"text\"][:150].replace(\"\\n\", \" \") # Corrected indentation\n",
    "    print(f\"   - Text: {text_previeww}...\") # Corrected variable name: 'text_preview' to 'text_previeww'\n",
    "    label = example[\"label\"]\n",
    "    print(f\"   - Label: {label} ({'Positive' if label == 1 else 'Negative'})\") # Adjusted indentation\n",
    "\n",
    "# label distribution\n",
    "  print(\"\\n4. Label distribution (train split):\")\n",
    "  labels = dataset[\"train\"][\"label\"]\n",
    "  positive_count = sum(labels)\n",
    "  negative_count = len(labels) - positive_count\n",
    "\n",
    "  print(f\"   - Positive reviews: {positive_count:,} ({positive_count/len(labels)*100:.1f}%)\") # Corrected variable name: 'train_labels' to 'labels'\n",
    "  print(f\"   - Negative reviews: {negative_count:,} ({negative_count/len(labels)*100:.1f}%)\") # Corrected variable name: 'train_labels' to 'labels'\n",
    "\n",
    "# Text length analysis\n",
    "  text_lengths = [len(text.split()) for text in dataset[\"train\"][\"text\"][:2000]] # Corrected indentation\n",
    "  print(\"\\n5. Average review length (first 2000 samples):\") # Corrected indentation\n",
    "  print(f\"   - Avg words per review: {np.mean(text_lengths):.1f}\")\n",
    "  print(f\"   - Max words: {np.max(text_lengths)}\")\n",
    "  print(f\"   - Min words: {np.min(text_lengths)}\")\n",
    "\n",
    "  print(\"\\nDataset exploration complete.\") # Corrected indentation\n",
    "  return dataset\n",
    "\n",
    "dataset = load_and_explore_data()\n",
    "print(\"\\n Data set loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c852aa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model intialization\n",
    "print(\"Intialize BERT model\")\n",
    "print(\"=\" *35)\n",
    "\n",
    "def initialize_bert_model():\n",
    "  \"\"\"Intializing DistilBERT model and tokenizer with professional setup\"\"\"\n",
    "  model_name=\"distilbert-base-uncase\"\n",
    "\n",
    "  print(f\"1. Loading tokenizer: {model_name}\")\n",
    "  tokenizer = AutoTokenizer.form_pretrained(model_name)\n",
    "\n",
    "  print(f\"2. Loading pre-trained model...\")\n",
    "  model = AutoModelForSequenceClassification.form_pretrained(model_name,\n",
    "                                                             num_labels=2,\n",
    "                                                             id2label={0: \"Negative\", 1: \"Positive\"},\n",
    "                                                             label2id={\"Negative\": 0, \"Positive\": 1}\n",
    "                                                             )\n",
    "  print(\"3. Model architecture overview:\")\n",
    "  print(\"f Model type: {model.__class__.__name__}\")\n",
    "  print(f\" Number of parameters: {model.num_parameters():,}\")\n",
    "  print(f\" Number of labels: {model.config.num_labels}\")\n",
    "  \n",
    "  print(\"4. Moving model to GPU...\")\n",
    "  if torch.cuda.is_available:\n",
    "    model=model.to('cuda')\n",
    "    print(\" Model succesfully moved to GPU\")\n",
    "\n",
    "    return tokenizer, model\n",
    "\n",
    "  # intialize model\n",
    "  tokenizer, model = initialize_bert_model()\n",
    "  print(\"BERT model intialized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133960f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Data Preprocessing & Tokenization\n",
    "print(\"DATA PREPROCESSING & TOKENIZATION\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "def preprocess_data(tokenizer, dataset):\n",
    "    \"\"\"Tokenize and prepare dataset for training\"\"\"\n",
    "    print(\"1. Defining tokenization function...\")\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        # Return as PyTorch tensors\n",
    "        return tokenizer(\n",
    "            examples[\"text\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=256\n",
    "        )\n",
    "\n",
    "    print(\"2. Tokenizing training dataset...\")\n",
    "    tokenized_train = dataset[\"train\"].map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        batch_size=1000\n",
    "    )\n",
    "\n",
    "    print(\"3. Tokenizing test dataset...\")\n",
    "    tokenized_test = dataset[\"test\"].map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        batch_size=1000\n",
    "    )\n",
    "\n",
    "    print(\"4. Dataset overview after tokenization:\")\n",
    "    print(f\"   - Training features: {list(tokenized_train.features.keys())}\")\n",
    "\n",
    "    # --- Diagnosis: Inspect the output of tokenization for a single sample ---\n",
    "    print(\"\\n--- Diagnosis of tokenized output ---\")\n",
    "    first_example_input_ids = tokenized_train[0]['input_ids']\n",
    "    print(f\"Type of tokenized_train[0]['input_ids']: {type(first_example_input_ids)}\")\n",
    "    if isinstance(first_example_input_ids, list):\n",
    "        print(f\"Length of the list: {len(first_example_input_ids)}\")\n",
    "        if len(first_example_input_ids) > 0:\n",
    "            print(f\"Type of the first element in the list: {type(first_example_input_ids[0])}\")\n",
    "            # If the first element is a tensor, get its shape\n",
    "            if isinstance(first_example_input_ids[0], torch.Tensor):\n",
    "                 print(f\"Shape of the first element (tensor): {first_example_input_ids[0].shape}\")\n",
    "            else:\n",
    "                # If the first element is not a tensor, try to convert and print shape\n",
    "                try:\n",
    "                    temp_tensor = torch.tensor(first_example_input_ids[0])\n",
    "                    print(f\"Shape after converting first element to tensor: {temp_tensor.shape}\")\n",
    "                except:\n",
    "                    print(\"Could not convert the first element to a tensor.\")\n",
    "    else:\n",
    "        # If it's not a list, assume it's a tensor and print its shape\n",
    "        print(f\"Input shape: {first_example_input_ids.shape}\")\n",
    "    print(\"-------------------------------------\")\n",
    "    # --- End of Diagnosis ---\n",
    "\n",
    "    # Original line causing error - will be skipped in diagnosis phase\n",
    "    # print(f\"   - Input shape: {tokenized_train[0]['input_ids'].shape}\")\n",
    "\n",
    "\n",
    "    return tokenized_train, tokenized_test\n",
    "\n",
    "# Preprocess data\n",
    "tokenized_train, tokenized_test = preprocess_data(tokenizer, dataset)\n",
    "print(\"DATA PREPROCESSING COMPLETED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2181a6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments # Add this import\n",
    "\n",
    "print(\" TRAINING CONFIGURATION\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "def setup_training():\n",
    "    \"\"\"Configure professional training parameters\"\"\"\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        # Output settings\n",
    "        output_dir=\"./results\",\n",
    "        overwrite_output_dir=True,\n",
    "\n",
    "        # Training parameters\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,\n",
    "\n",
    "        # Evaluation settings\n",
    "        # Changed evaluation_strategy to eval_strategy\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "\n",
    "        # Logging\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=500,\n",
    "        report_to=\"none\",\n",
    "\n",
    "        # Optimization\n",
    "        warmup_steps=500,\n",
    "        fp16=torch.cuda.is_available(),  # Use mixed precision if GPU available\n",
    "    )\n",
    "\n",
    "    print(\" TRAINING CONFIGURATION:\")\n",
    "    print(f\"   - Epochs: {training_args.num_train_epochs}\")\n",
    "    print(f\"   - Batch size: {training_args.per_device_train_batch_size}\")\n",
    "    print(f\"   - Learning rate: {training_args.learning_rate}\")\n",
    "    print(f\"   - Evaluation: {training_args.eval_strategy}\") # Changed to eval_strategy\n",
    "    print(f\"   - FP16 (speedup): {training_args.fp16}\")\n",
    "\n",
    "    return training_args\n",
    "\n",
    "training_args = setup_training()\n",
    "print(\" TRAINING CONFIGURATION COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd23aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Evaluation Metrics & Trainer\n",
    "from sklearn.metrics import accuracy_score, f1_score # Import metrics\n",
    "from transformers import Trainer # Import Trainer class\n",
    "\n",
    "print(\" EVALUATION METRICS SETUP\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute  evaluation metrics\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average=\"weighted\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_score\": f1,\n",
    "        \"error_rate\": 1 - accuracy\n",
    "    }\n",
    "\n",
    "# fix dataset labels and set format (moved outside compute_metrics if they were inside)\n",
    "# Note: These operations should be done once before Trainer setup\n",
    "tokenized_train = tokenized_train.rename_column(\"label\",\"labels\")\n",
    "tokenized_test = tokenized_test.rename_column(\"label\", \"labels\") # Fixed typo 'lables'\n",
    "\n",
    "tokenized_train.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "tokenized_test.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "print(\"1. Setting up Trainer...\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(\"2. Trainer configuration:\")\n",
    "print(f\"   - Training samples: {len(tokenized_train):,}\")\n",
    "print(f\"   - Evaluation samples: {len(tokenized_test):,}\")\n",
    "print(f\"   - Total steps: {training_args.num_train_epochs * len(tokenized_train) // training_args.per_device_train_batch_size:,}\")\n",
    "\n",
    "print(\"TRAINER SETUP COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c663c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: MODEL TRAINING EXECUTION\n",
    "print(\"üèãÔ∏è STARTING MODEL TRAINING\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "print(\"1.  TRAINING OVERVIEW:\")\n",
    "print(f\"   - Model: DistilBERT (BERT's faster cousin)\")\n",
    "print(f\"   - Task: Learn if movie reviews are Positive or Negative\")\n",
    "print(f\"   - Data: 25,000 movie reviews\")\n",
    "print(f\"   - Time: 20-30 minutes with GPU\")\n",
    "\n",
    "print(\"\\n2. TRAINING STARTED...\")\n",
    "print(\"   This is where your AI learns from the data!\")\n",
    "print(\"   The coach (Trainer) is now teaching your model...\")\n",
    "print(\"   Grab a coffee!\")\n",
    "\n",
    "# THIS IS WHERE MAGIC HAPPENS!\n",
    "training_results = trainer.train()\n",
    "\n",
    "print(\"\\n3. TRAINING COMPLETED!\")\n",
    "print(\"=\" * 30)\n",
    "print(\"   Your AI has finished learning!\")\n",
    "print(\"   Now let's see how well it learned...\")\n",
    "\n",
    "# Show training results\n",
    "print(f\"   - Total time: {training_results.metrics['train_runtime']:.0f} seconds\")\n",
    "print(f\"   - Final loss: {training_results.metrics['train_loss']:.4f}\")\n",
    "print(f\"   - Speed: {training_results.metrics['train_samples_per_second']:.1f} samples/second\")\n",
    "\n",
    "print(\"\\nüéâ PHASE 1 COMPLETE: MODEL IS TRAINED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ba7114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "print(\"TESTING AI KNOWLEGDE\")\n",
    "print(\"=\" *35)\n",
    "\n",
    "print(\"1.  FINAL EXAM TIME!\")\n",
    "print(\"   Now testing your model on 25,000 NEW reviews\")\n",
    "print(\"   It has never seen these before!\")\n",
    "\n",
    "# test the model\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(\"\\n2.  EXAM RESULTS:\")\n",
    "print(\"   \" + \"=\"*20)\n",
    "accuracy = eval_results['eval_accuracy']\n",
    "f1 = eval_results['eval_f1_score']\n",
    "\n",
    "print(f\"   Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"    F1-Score: {f1:.4f}\")\n",
    "print(f\"    Error Rate: {1-accuracy:.4f} ({(1-accuracy)*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n3.  GRADE INTERPRETATION:\")\n",
    "if accuracy > 0.92:\n",
    "    print(\"    EXCELLENT! Your AI is smarter than 92% of humans!\")\n",
    "elif accuracy > 0.88:\n",
    "    print(\"    VERY GOOD! Professional-level performance!\")\n",
    "elif accuracy > 0.85:\n",
    "    print(\"    GOOD! Solid understanding of sentiment!\")\n",
    "else:\n",
    "    print(\"    NEEDS PRACTICE! But still better than guessing!\")\n",
    "\n",
    "print(f\"\\n4. RANDOM GUESS COMPARISON:\")\n",
    "print(f\"   - Random guessing: 50.00%\")\n",
    "print(f\"   - Your AI: {accuracy*100:.2f}%\")\n",
    "print(f\"   - Improvement: +{(accuracy-0.5)*100:.2f}%\")\n",
    "\n",
    "print(\"\\n PHASE 2 COMPLETE: MODEL EVALUATED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac42470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: COMPREHENSIVE ANALYSIS & MODEL SAVING\n",
    "print(\"COMPREHENSIVE PERFORMANCE ANALYSIS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "print(\"1. DETAILED PERFORMANCE BREAKDOWN:\")\n",
    "print(\"   \" + \"=\"*30)\n",
    "\n",
    "# Get your evaluation results (from Cell 8)\n",
    "accuracy = eval_results['eval_accuracy']\n",
    "f1 = eval_results['eval_f1_score']\n",
    "error_rate = 1 - accuracy\n",
    "\n",
    "print(f\"   Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"   F1-Score: {f1:.4f}\")\n",
    "print(f\"    Error Rate: {error_rate:.4f} ({error_rate*100:.2f}%)\")\n",
    "print(f\"    Evaluation Loss: {eval_results['eval_loss']:.4f}\")\n",
    "\n",
    "print(\"\\n2.  PERFORMANCE BENCHMARKING:\")\n",
    "if accuracy > 0.92:\n",
    "    print(\"    EXCELLENT! State-of-the-art performance!\")\n",
    "    print(\"   Your model outperforms most commercial systems!\")\n",
    "elif accuracy > 0.88:\n",
    "    print(\"    VERY GOOD! Professional-grade AI!\")\n",
    "    print(\"   Your model understands sentiment exceptionally well!\")\n",
    "elif accuracy > 0.85:\n",
    "    print(\"    GOOD! Solid commercial performance!\")\n",
    "    print(\"   Your model learned the patterns effectively!\")\n",
    "else:\n",
    "    print(\"    SATISFACTORY! Good learning achieved!\")\n",
    "    print(\"   Your model significantly beats random guessing!\")\n",
    "\n",
    "print(f\"\\n3. INDUSTRY COMPARISON:\")\n",
    "print(f\"   - Random Guessing: 50.00%\")\n",
    "print(f\"   - Basic AI Models: 70-80%\")\n",
    "print(f\"   - Commercial Systems: 85-90%\")\n",
    "print(f\"   - Your Model: {accuracy*100:.2f}%\")\n",
    "print(f\"   - Research State-of-Art: 92-95%\")\n",
    "\n",
    "print(f\"\\n4. TECHNICAL PERFORMANCE:\")\n",
    "print(f\"   - Evaluation Time: {eval_results['eval_runtime']:.2f} seconds\")\n",
    "print(f\"   - Samples Processed: {len(tokenized_test):,}\")\n",
    "print(f\"   - Processing Speed: {eval_results['eval_samples_per_second']:.1f} samples/second\")\n",
    "\n",
    "print(\"\\n5.  SAVING YOUR TRAINED MODEL...\")\n",
    "model_save_path = \"/content/models/sentiment_model\"\n",
    "\n",
    "# Save your trained model\n",
    "trainer.save_model(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "print(\"    Model saved successfully!\")\n",
    "print(f\"   Location: {model_save_path}\")\n",
    "\n",
    "print(\"\\n CELL 9 COMPLETE: ANALYSIS DONE & MODEL SAVED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c19b213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: COMPLETE MODEL SAVING SOLUTION\n",
    "print(\"COMPREHENSIVE MODEL SAVING\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(\"1. SAVING MODEL FILES IN COLAB...\")\n",
    "model_save_path = \"/content/models/sentiment_model\"\n",
    "\n",
    "# Save model components\n",
    "trainer.save_model(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "print(\"2. MODEL COMPONENTS SAVED:\")\n",
    "import os\n",
    "model_files = os.listdir(model_save_path)\n",
    "for file in model_files:\n",
    "    file_size = os.path.getsize(f\"{model_save_path}/{file}\") / (1024*1024)\n",
    "    print(f\"    {file} ({file_size:.1f} MB)\")\n",
    "\n",
    "print(\"\\n3. CREATING PROFESSIONAL DOCUMENTATION...\")\n",
    "model_card = f\"\"\"\n",
    "#  Custom Sentiment Analysis Model\n",
    "\n",
    "## Quick Facts\n",
    "- **Accuracy**: {accuracy*100:.2f}% on IMDB test set\n",
    "- **Size**: ~250MB\n",
    "- **Training Time**: 30 minutes\n",
    "- **Best For**: Movie reviews, product reviews, social media\n",
    "\n",
    "## Files Included\n",
    "- `pytorch_model.bin` - AI model weights\n",
    "- `config.json` - Model architecture  \n",
    "- `tokenizer.json` - Text processing rules\n",
    "- `README.md` - This documentation\n",
    "\n",
    "## Usage\n",
    "```python\n",
    "from transformers import pipeline\n",
    "model = pipeline(\"sentiment-analysis\", \n",
    "                model=\"path/to/sentiment_model\")\n",
    "result = model(\"This movie was amazing!\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b192573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: LIVE DEMO CREATION\n",
    "print(\" CREATING LIVE DEMO INTERFACE\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(\"1. üîÑ LOADING YOUR TRAINED MODEL...\")\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load YOUR custom trained model (not a pre-trained one!)\n",
    "sentiment_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model_save_path,  # This is YOUR model\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(\"2. ‚úÖ MODEL LOADED SUCCESSFULLY!\")\n",
    "print(f\"   - Model: {model_save_path}\")\n",
    "print(f\"   - Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"   - Training: 25,000 IMDB reviews\")\n",
    "\n",
    "print(\"\\n3. üé™ CREATING PREDICTION FUNCTION...\")\n",
    "def analyze_sentiment(text):\n",
    "    \"\"\"\n",
    "    This function uses YOUR custom trained model to analyze sentiment\n",
    "    \"\"\"\n",
    "    if not text.strip():\n",
    "        return \"‚ùå Please enter some text to analyze!\"\n",
    "    \n",
    "    try:\n",
    "        # Get prediction from YOUR trained model\n",
    "        result = sentiment_pipeline(text)[0]\n",
    "        \n",
    "        # Convert model output to readable format\n",
    "        label = \"Positive\" if result['label'] == 'LABEL_1' else \"Negative\"\n",
    "        confidence = result['score']\n",
    "        \n",
    "        # Create professional output\n",
    "        output = f\"\"\"üéØ SENTIMENT: {label.upper()}\n",
    "üìä CONFIDENCE: {confidence:.2%}\n",
    "üí¨ ANALYSIS: {'üòä Positive emotion detected' if label == 'Positive' else 'üòû Negative emotion detected'}\n",
    "‚≠ê MODEL PERFORMANCE: {accuracy*100:.1f}% accurate on test data\n",
    "\n",
    "üîç DETAILS:\n",
    "- Model: Your Custom DistilBERT\n",
    "- Training: 25,000 IMDB reviews\n",
    "- Task: Binary sentiment classification\"\"\"\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error in analysis: {str(e)}\"\n",
    "\n",
    "print(\"4. üñ•Ô∏è BUILDING PROFESSIONAL WEB INTERFACE...\")\n",
    "demo = gr.Interface(\n",
    "    fn=analyze_sentiment,  # Function to call\n",
    "    inputs=gr.Textbox(\n",
    "        lines=3,\n",
    "        placeholder=\"Enter your movie review, product feedback, or any text here...\",\n",
    "        label=\"üìù TEXT TO ANALYZE\"\n",
    "    ),\n",
    "    outputs=gr.Textbox(\n",
    "        label=\"üéØ SENTIMENT ANALYSIS RESULT\",\n",
    "        show_copy_button=True\n",
    "    ),\n",
    "    title=\"üé¨ AI SENTIMENT ANALYZER - YOUR CUSTOM MODEL\",\n",
    "    description=f\"\"\"**ü§ñ Powered by YOUR Custom AI Model**\n",
    "\n",
    "üìä **Model Performance:** {accuracy*100:.2f}% accuracy | Trained on IMDB reviews\n",
    "\n",
    "‚ú® **Features:**\n",
    "- Real-time sentiment analysis\n",
    "- Confidence scoring\n",
    "- Professional-grade AI\n",
    "- Your custom trained model\n",
    "\n",
    "**Enter any text and see YOUR AI in action!**\"\"\",\n",
    "    \n",
    "    examples=[\n",
    "        [\"This movie was absolutely fantastic! The acting was superb and the story was captivating from beginning to end.\"],\n",
    "        [\"I hated this film. It was boring, poorly acted, and the plot made no sense whatsoever. Waste of time.\"],\n",
    "        [\"The cinematography was beautiful and visually stunning, but the characters were poorly developed and shallow.\"],\n",
    "        [\"One of the best movies I've ever seen! The direction, acting, and screenplay were all perfect. Highly recommended!\"],\n",
    "        [\"Terrible movie with awful acting and a confusing storyline. I regret spending money on this.\"],\n",
    "        [\"It was okay, nothing special. Some good moments but overall pretty mediocre and forgettable.\"]\n",
    "    ],\n",
    "    theme=\"soft\"\n",
    ")\n",
    "\n",
    "print(\"5. üöÄ LAUNCHING LIVE DEMO...\")\n",
    "print(\"   \" + \"=\"*30)\n",
    "print(\"   ‚≠ê **IMPORTANT FOR YOUR PROJECT:** ‚≠ê\")\n",
    "print(\"   - A new tab will open with your demo\")\n",
    "print(\"   - You will get a PUBLIC URL\")\n",
    "print(\"   - SHARE THIS URL WITH YOUR PROFESSOR!\")\n",
    "print(\"   - This demonstrates your working AI system!\")\n",
    "print(\"   \" + \"=\"*30)\n",
    "\n",
    "# Launch the demo with public sharing\n",
    "demo.launch(share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
